
# 提升AI算法在多端落地性能 基于开源模型结构重新设计更优模型结构
1. 从工程角度微调模型，设计出更规整的模型性，降低模型转换过程中算子缺失的概率
2. 从工程角度微调模型，设计出更易图优化的模型结构
3. 从算法角度出发，设计性能更好的模型结构（比如更换backbone）
   
4. 模型蒸馏、剪枝工具
5. 使用特定推理框架提供量化工具，无法自适应的量化
6. 适配量化修改对应推理框架
7. 图优化工作未开始 1. 算法与工程共同优化模型
8. 建立模型蒸馏、剪枝通用工具
9.  自适应量化工具并针对编写高息能工具
10. 手动融合算子并针对编写高性能算子 1. 特定推理框架的量化部署
11. 手动算子融合并针对特定推理框架的自定义算子
  
# 通用的模型轻量化平台
1. 模型蒸馏
2. 模型剪枝
3. 量化 
   
# 模型图优化
1. 自动模型图优化
2. 手动图优化（eg: 在tensor_rt中将一系列连续的图形操作类算子替换为一个自定义plugin）
   
# 推理框架
1. 推理框架高级的使用方式（eg: openvino中的高带宽、CPU-GPU的执行方式）
2. 推理框架输入输出零拷贝
3. 自定义算子（算子转换、算子解释、高性能算子）
3.1 模型转换时算子缺失
3.2 适配图优化做自定义算子
3.3 适配量化做量化算子（像openvino一样做深度量化）
1. 前后处理
2. 端侧cpu占用率
3. 内存资源
4. 初始化耗时
5. c++代码优化（内存预分配、多线程使用等） 1. 较好的使用推理框架
6. 未很好的实现推理框架输入输出零拷贝
7. 具备一定自定义算子能力
8. 编写了部分前后处理高性能算子
9. 较好的c++代码优化 1. 增强自定义算子能力
10. 开发图像基础库
11. 进一步c++代码优化  
  
# 特殊硬件支持
1. android 高通hvx平台 的 snpe推理框架
2. android 联发科平台 的 推理框架