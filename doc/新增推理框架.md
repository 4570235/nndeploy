# 如何新增推理框架
主要可以被分为三个部分：理解nndeploy的推理模块；理解需要接入的推理框架；nndeploy的推理模块去封装需要接入的推理框架

## 理解nndeploy的推理模块
通过调用nndeploy一套推理的接口，可以实现调用任意推理框架，nndeploy的接口可以被认为是算法与推理框架之间的中间层。
nndeploy推理可以分为三个部分：
+ nndeploy的推理类nndeploy::inference::Inference(详细阅读include\nndeploy\inference\inference_param.h，该文件有较为详细的注释)
+ nndeploy的推理类的超参数配置类nndeploy::inference::InferenceParam(详细阅读include\nndeploy\inference\inference.h，该文件有较为详细的注释)
+ 用于推理的Tensor类nndeploy::device::Tensor(详细阅读include\nndeploy\device\tensor.h，该文件有较为详细的注释)
  
## 理解需要接入的推理框架
主要去理解对应推理框架的用法以及对外导出的头文件

## nndeploy的推理模块去封装需要接入的推理框架(这里以MNN为例)
+ mnn_include.h 
  + 作用：包含需接入推理框架mnn的头文件
+ mnn_inference_param.h mnn_inference_param.cc
  + 作用：主要完成对MNN所有推理配置的封装
  + 实现方式：MnnInferenceParam继承InferenceParam，在MnnInferenceParam添加InferenceParam没有的属性
+ mnn_inference.h mnn_inference.cc
  + 作用：主要完成对MNN推理的封装
  + 实现方式：MnnInference继承Inference，通过mnn的接口实现Inference中的virtual接口
+ mnn_convert.h mnn_convert.cc
  + 作用：主要是如下两方面的作用
    + nndeploy推理类接受的数据类型为nndeploy推理配置类，在选择mnn推理时，需要把nndeploy推理配置类转换为mnn的推理配置类。故需要把nndeploy中定义的一套推理的配置的数据结构（主要是枚举）与 mnn中定义的一套推理配置的数据结构进行相互转换
    + nndeploy推理类处理的数据类型nndeploy::device::Tensor，在选择mnn推理时，需要把nndeploy::device::Tensor转换为MNN::Tensor。考虑到性能的原因，nndeploy::device::Tensor与MNN::Tensor进行相互转换，但数据为浅拷贝