
# 提升AI算法在多端落地性能 基于开源模型结构重新设计更优模型结构
1. 从工程角度微调模型，设计出更规整的模型性，降低模型转换过程中算子缺失的概率
2. 从工程角度微调模型，设计出更易图优化的模型结构
3. 从算法角度出发，设计性能更好的模型结构（比如更换backbone）
     
# 通用的模型轻量化平台(对于模型分级特别有用)
1. 模型蒸馏
2. 模型剪枝

# 模型量化
3. 量化 
   1. 深度量化 （eg: openvino）
      1. 针对特定推理框架大改
   2. 自适应量化
      1. 效果
      2. 性能 
   
# 模型图优化
1. 自动模型图优化
2. 手动图优化（eg: 在tensor_rt中将一系列连续的图形操作类算子替换为一个自定义plugin）
   
# 推理框架
1. 推理框架高级的使用方式（eg: openvino中的高带宽、CPU-GPU的执行方式）
2. 推理框架输入输出零拷贝
3. 自定义算子（算子转换、算子解释、高性能算子）
   1. 型转换时算子缺失
   2. 适配图优化做自定义算子
   3. 适配量化做量化算子（像openvino一样做深度量化）
4. 前后处理
5. 内存资源
6. 初始化耗时
7. c++代码优化
   1. 内存预分配
   2. 异构并行
      1. 模型内并行 -- 寻找到模型本身可以并行的部分
      2. 模型外并行 -- 同一模型 开启多个 推理实例（openvino、tensor_rt）
   3. 常用的的优化技术
  
# 特殊硬件支持
1. android 高通hvx平台 的 snpe推理框架
2. android 联发科平台 的 推理框架

# 插件化